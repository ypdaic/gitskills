es 分词器使用tokenizer表示，默认提供的如下

1：标准分词器 standard
2: 关键字分词器 keyword (也就是不分词)
3：字母分词器 letter
4: 小写分词器 （字母分词器 + 小写分词过滤器）
5：空白分词器
6：模式分词器
7：UAX,URL 电子邮件分词器
8: 路径层次分词器  如：/usr/local/var/log/elk.log 每个目录一个分词一下
1: 创建采集目录

     mkdir conf.d
     vi config.conf

     config.conf 文件内容如下：

        input {
            file {
                # 采集文件目录
                path => "/root/logs/*.log"
                # 从文件的什么位置采集
                start_position => beginning
                # 表示文件从哪里来的，信息可以自定义
                add_field => {"from" => "localfile"}
            }
            kafka {
                bootstrap_servers => ["192.168.109.129:9092"]
                group_id => "logstash"
                topics => ["demo"]
                consumer_threads => 1
                decorate_events => true
                add_field => {"from" => "demo "}
                codec => "json" #filedeat 过来的数据为json
            }

        }
        # filedeat 对文件进行过滤
        filter {
            # 合并filebeat 的host.name 属性
            mutate {
                rename => { "[host][name] => "host"}
            }
        }
        # 输出
        output {
          # 向es输出
          elasticsearch {
                # es 主机
                hosts => ["192.168.109.129:9200"]
                # 放到es的那个索引下
                index => "mylog"
          }
          stdout {

          }
        }

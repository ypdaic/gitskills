
cyclicBarrier 和 countDown用法上的区别：

前者是多个线程相互等待然后一起执行，后者是一个线程等待多个线程然后执行

常用spring的接口：

    BeanNameAware,BeanClassLoaderAware,BeanFactoryAware，ApplicationContextAware，InitializingBean，SmartLifecycle,

redis 实现分布式锁

    SET resource_name my_random_value NX PX 30000   值是一个随机值，必须保证唯一性

    解锁用lua脚本去解锁，防止，A线程锁超时后，B线程获取锁成功，A将B的锁给删除掉


Bean的生命周期

    1. 实例化bean
    2. bean 属性设置
    3. arwe接口处理
    4. beanpostprocess 接口前置处理
    5. InitializingBean 接口处理
    6. beanpostprocess 接口后置处理
    7. bean的销毁处理

IOC、AOP

    IOC 就是所有的对象交给spring容器管理，对象的创建，销毁，属性的主动注入
    AOP 就是提供一些切面功能，比如事务切面，缓存切面，等等，核心就是使用代理模式，使用生成的代理实例替代原有的bean，在
        原有bean方法的前后执行一些而外的逻辑，其代理模式有分为jdk动态代理，cglib代理，jdk动态代理只能是对接口进行代理，而
        cglib使用的继承进行代理，也支持只对接口代理，spring默认使用cglib进行代理

HashTable、HashMap、ConcurrentHashMap

    HashTable 是线程安全的，使用sync进行同步，而HashMap 不是线程安全的，ConcurrentHashMap是线程安全的
    ConcurrentHashMap在1.8以前使用分段锁思想，1.8以后则将锁细分到每个node节点，这样并发性能更高

数据库事务的底层实现、Spring事务是如何实现的

    事务底层使用mvcc多版本控制实现的，spring事务则是使用threadlocal将数据源绑定到当前线程上，然后开启事务，后续当前线程的数据库操作
    则在这个事务上进行，spring自己给提供了一个事务传播机制，大概弄了7种传播机制，
    如果当前没有事务，则开启一个事务，
    如果当前没有事务则报错，
    如果当前没有事务则已非事务进行，有事务则在事务中进行
    当前有事务则挂起该事务以非事务的方式执行，
    当前有事务，挂起该事务，并继续使用该事务执行，如果出现错误，则只是回滚挂起点之后的
    当前有事务则挂起该事务，后面开启一个新的事务执行，

Spring如何解决循环依赖

    使用3级缓存解决的，第一级缓存存放实例化完成的对象，第二级缓存存放提前暴露的对象，第三级缓存放对象工厂对象
    解决循环依赖就依靠这三级缓存解决的，比如A依赖b,b依赖c,c又依赖A，当实例化A时，必然要先实例化B，c,而C
    的实例化又依赖A，此时就会回到创建A的逻辑，而在第一次创建A时已经将其放到了第3级缓存中，创建C的过程中
    依赖A就会直接重三级缓存中获取A，并且将三级缓存清空，将其提升到二级缓存，此时二级缓存是一个提前暴露的对象
    如果还存在C中d对象也依赖A的话，就直接从二级缓存中获取，最后A创建完成将二级缓存清空，提升到一级缓存，后面其他对象
    依赖A就直接从一级缓存中获取

线程池的参数及执言行过程

   核心线程池的大小，最大线程池大小，线程空闲时间及空闲时间的单位，阻塞队列，线程工厂，拒绝策略

   执行逻辑就是，当任务数小于核心线程数大小时，则开启新的线程用于处理任务，如果大于核心大小，则将任务放到阻塞队列，如果
   队列满了，则创建新的线程处理任务，如果线程数等于最大线程数了，则要使用拒绝策略了，比如抛异常，或者直接使用丢任务的线程处理，
   或者丢弃老的任务，或者丢弃该任务，当大于核心线程数的线程执行完任务开始获取下一个任务执行时，如果获取时间超过设置的空闲时间
   则该线程会被销毁，也就是超过核心的线程使用poll去获取任务，小于核心数的线程使用take去获取任务

   线程池的销毁也分两组情况，一种是shutdown，一种是shutdownnow ,前者会执行完队列中的任务，并且不会发送中断给线程池中正在执行任务的线程
   后者则是会将队列中的任务拿出来给调用者自己决定要怎么处理这些任务， 并且会发送中断给正在执行任务的线程

MySQL的乐观锁、悲观锁

    乐观锁就是使用版本号，使用cas的思想，循环不断的去比较当前版本号和数据库的版本号是否一致，一致就更新，不一致就是重新获取最新的
    版本号，进行下一次的判断更新

    悲观锁就是上来就加一把锁，如果加锁失败就等待锁，比如使用select for update ，获取锁后在进行下面的操作，
    如果有使用到索引就是行锁，如果没有使用索引则就是表锁

MVCC机制的实现

    其实现就是在开启事务前，会将当前最新的事务id，保存为up_limit_id
    如果更新一条数据的话，则会将这个数据的就记录以及该数据的事务id存到undo_log 中
    然后更新数据页中该记录的值和事务id
    当别的事务要查询该条记录时，如果自己的up_limit_id 小于该条记录的事务id，则会去undo_log中查找，也是找事务id小于up_limit_id的记录


SpringBoot的整个启动流程

    整个逻辑就是从spring.fatoryas 文件中搜集springApplicationrunlister接口的实现
    然后调用starting接口
    然后是环境信前置处理，调用lisenler接口的preaper环境接口
    然后打印banner
    然后开始创建ApplicationContext,这其中开始收集注解，自动配置的配置类，生成beandefeintion对象，然后调用onrefresh方法
    进行webserver的创建，也就tomcat的初始后，
    然后开始bean的创建过程
    这些完毕后，就会调用前面lisenler接口的stared接口
    最后调用ApplicationRunner,CommandLineRunner接口


cglib 和 jdk动态代理的区别

重要的一点在用法上如果注入的具体的实例，jdk动态代理会报类型转换异常，然后CGLIB 默认是自动配置进行配置的


ES的倒排索引、查询的整个流程、如何动态加载新的分词
Java异常类的层次结构

    throwable

     error   exception

             runtimeexcetion

redis的常用数据结构及底层实现



redis、zk的分布式锁的实现

     redis setnx 命令，保证只有有一个线程设置成功
           其次要解决客户端假死，锁无法释放的问题，需要设置锁的过期时间
           还有解决业务执行的时间超过锁过期时间，需要使用定时任务去给锁进行续期
           还要解决锁被误解锁问题，需要使用lua脚本判断该锁的随机码和内存中持有的是否一致
           一致才能释放锁
           还要解决锁重入问题，可以使用threadlocal保存当前线程，如果下次获取锁的还是当前线程者不用再次获取锁了
           直接执行

     zk   主要使用临时有序节点，最小的节点最先获取锁，后续的节点监听前面节点的删除事件，被通知后才进行锁的获取
          由于临时节点不存死锁问题，需要设置锁的过期时间和续期问题，重入可以和redisd的做法一样

rabbitmq如何保证消息的可靠性、顺序性、幂等消费，及使用场景

    rabbitmq 消息可靠性保证可以使用发送者确认和失败通知模式，还有消费者应答模式，结合本地消息表形式加定时任务的
    顺序性生产者使用一个channel进行发送，消费者使用一个队列进行消费，幂等需要在每条消息中加入一个唯一码，使用这个唯一码去查询这个
    消息是否被消费过，消费了就不进行消费了



分布式事务（2pc、3pc、TCC、阿里的seata框架的大概执行流程）

    TCC 主要分为3个过程try,commit，cancer
    try 主要是预留资源
    commit 就是对预留资源处理
    cancer 就是回退预留的资源
    都需要业务端实现

    seata AT 事务，比如在A服务开启全局事务，A需要开启本地事务，然后会生成beforeimage 执行本地事务，afterimage, 和本地事务一起插入到undo_log表中g

    然后开始调用B服务，比如是使用fegin调用的，此时会将全局事务id放到fegin的请求头中，B服务使用springmvc的拦截器获取到全局事务id，并绑定到当前线程中
    然后数据源代理对象检测到存在全局事务id后，一样会生成beforeimage afterimage 和本地事务一起插入到undo_log表中，并且向TM插入一个分支事务
    然后提交本地事务，向TM上报分支事务执行状态，此时回到A服务，也是注册分支事务，如果此时发生异常，会上报分支事务的状态，本地事务回滚，TM是发送异步回滚事件通知
    B服务进行回滚，回滚就将数据更新成beforeimage的状态

CAS、volatile、Java内存模型、内存屏障

   CAS 就是比较与交换，使用内存中的值和主内存中值进行比较，如果相等则更新主内存中的值，如果不相等则获取最新主内存中的值，循环等待下次比较

   volatile 只能保证可见性，不能保证原子性，volatile可以防止指令重排序，防止指令重排序则依靠内存屏障，比如storestore,storeload,loadload,loadstore



JVM的堆外内存

   元空间

怎么判断可能存在内存泄漏


    多次full gc 回收的内存很小了，就可能存在内存泄漏

多大的对象直接放入到老生代

    -XX:PretenureSizeThreshold=4m

3色标记法

    黑色 gcroot
    灰色 正在扫描
    白色 已经扫描完成，并且可以被回收

CMS和G1的执行流程及G1的好处

    CMS

    初始标记，并发标记，重新标记，并发清除，初始标记和重新标记会有暂停，而并发标记，并发清除，则是和应用线程一起进行

    G1
    初始标记，并发标记，最终标记，筛选回收，初始标记，最终标记会有暂停，并发标记，筛选回收，则和应用程序一起进行
    G1 追求可以预测的挺顿

synchronized（jdk8的优化点）和reentrantLock的底层实现及区别

   锁升级，偏向锁，轻量级锁，重量级锁
   jdk 实现

AQS的组成及加锁过程

    AQS就是CLH队列锁的变种实现，内部使用node形成一个双向链表，每个node包含了前驱节点，后续节点和当前线程引用
    加锁过程就是，先获取信号量，如果获取信号量失败就创建一个等待node节点，添加到队列尾部，设置前驱节点，然后判断前驱
    节点是否是head节点，如果是的话，继续获取信号量，如果获取成功就加锁成功，如果获取失败就等待，等待被前驱节点唤醒

redo log、undo log、binlog的作用、两阶段提交…

 redo log 用于保证数据库crash_safe 的能力
 binlog 用于主从数据同步
 undo log 用于事务隔离

 两阶段提交：

    redo log perpra

     bin log 写入

     redo log 提交

     当在2之前崩溃时
     重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。一致

     当在3之前崩溃
     重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致

BIO、NIO、AIO的区别

    BIO 阻塞IO
    NIO 多路复用IO
    AIO 真正的异步IO

mmap、零拷贝

    零拷贝就是没有将堆外内存拷贝到堆内存的过程，而是直接操作堆外内存

类加载机制

    遵从找父类加载器进行加载，父类加载不到，自己才进行加载

dubbo的执行流程，http和RPC的关系，dubbo和SpringCloud Feign的区别

SpringBoot Starters的优点

    开发人员不用自己手动配置别人提供的功能，该配置那些功能，而且还能参考别人的配置，搞清楚该如何去配置去使用第三方提供的功能

按整个项目的执行流程，介绍SpringCloud的各个组件
访问域名www.baidu.com的整个流程
websocket的底层实现

缓存穿透、缓存雪崩、缓存击穿

   缓存穿透：就是使用多个不存在的key去请求，由于redis中没有，请求直接打到数据库了，解决方案有：回种空值，设置较短的过期时间，或者布隆过滤器
   缓存雪崩：大量key同时失效，导致请求全部打到数据库，解决方案：key的过期时间设置随机值，尽量分散开
   缓存击穿：单个key，被大量访问，解决方案：加锁，本地锁，分布式锁

缓存一致性协议（基于具体场景问题，忘记了）

redis哨兵如何通信


redis的过期策略

    惰性删除（get时才去删除），定期删除（随机取部分过期的key进行删除）

RDB、AOF

    RDB：内存数据的快照
    AOF：记录每个执行的每条命令，顺序写
    同时开启的话，加载的AOF

mysql索引优化

    explan 命令type至少是req级别
    1：是否走了索引，如果没有则优化sql利用索引
    2：检查利用的索引是否是最优索引
    3：检查所查字段是否都是必须的，是否查询了过多的字段，查出了多余数据
    4：检查表中数据是否过多，是否应该分库分表
    5：检查数据库实例所在机器的性能配置，是否太低，是否可以适当增加资源
   

mysql索引失效原因

     对索引字段进行函数计算，like方法，索引字段有空值，is null,is not null

mysql 死锁如何查询

    执行命令：show engine innodb status （需要在mysql的命令行执行）

mysql的逻辑架构组的组成

redis单线程为什么这么快

   1：基于纯内存操作
   2：IO多路复用，非阻塞的同时监听多个客户端的连接和相关事件
   3：单线程避免上下文切换，和资源竟态竞争


mysql主从复制流程

    master上有dump线程，每次数据变更，master会通知dump线程将数据发送slave,slave上有对应的IO线程和sql线程
    IO线程负责将master推送过来是数据写到relay-bin中，然后sql读取relay-bin的内容进行同步

    默认是异步的，也有半同步，也就是等slave的relay-bin 写成功后master才进行事务的提交

ThreadLoc的底层实现、为什么要使用弱引用，如何防止内存泄漏、开源代码及项目中的使用案例

    Thread 对象本身存在一个ThreadLocalMap 对象，
    以ThreadLocal 为key,存放的值为value
    使用弱引用，怕在线程周期中，ThreadLocal 对象的外部引用不存在，而由于线程一直在运行，ThreadLocalMap中的key,value本该被回收的，不能回收，造成
    内存泄漏，所以用了弱引用，只要GC就进行回收，防止内存泄漏：用于就得remove掉
    使用案例：spring 事务，动态数据源切换

如何解决跨域问题
CompletableFuture、Forkjoinpool的底层实现，该如何使用
介绍一款分布式ID

   雪花算法：41位时间戳，5位机房id,5位机器id,12位同一毫秒生成不同id

Hystrix的熔断、限流、降级

    如果没有触发熔断，且是线程池隔离，则会检查是否超过线程池任务处理数，如果是信号量隔离，则会检查是否能够获取信号量，不满足就走降级，
    如果都满足则会判断是否在时间窗口内超过20个请求，且失败率超过了50%，如果满足的话就会开启熔断，走降级，如果没有则正常请求
    如果已经触发熔断则会5秒中后探测一下是否请求成功，如果成功则关闭熔断，如果失败，再过5秒继续试探

分布式链路如何串联所有span的

TCP、UDP的区别

    TCP 需要客户端连接服务端
    UDP 直接广播

Object有哪些方法，为什么要重写hashcode和equals方法

    重写hashcode 是为了将对象放在MAP中时减少hash冲突
    重写equals 是为了将对象放在MAP中时，判断两个对象相等的依据

创建线程的几种方式，及区别

    实现Runable接口，继承Thread，实现Callable接口
    前两者没有返回值，后置存在返回值

单例对象创建的几种方式，并详细描述

    饱汉模式：类中定义好静态变量，并进行初始化
    懒汉模式：使用sync进行同步
    双重检查：当对象为空时才进行同步，进入到同步块中，再次判断是否为空，为空才进行初始化，初始化后赋值的变量得用volatile修饰，防止指令重排序，类还没初始化完成就被使用的情况

zk的脑裂、选主流程、如何防止脑裂

    脑裂就是zk集群部署在多个机房，两个机房断联了，然后每个机房各自开始进行选主，但是zk是不可能出现脑裂的，比如每个机房3个节点
    选主需要超过半数节点的投票，由于总共6个节点，超过半数就是超过3个节点，然而每个机房只有3个节点，所以整个集群就不可用了，不存在脑裂

    防止脑裂还是要合理的部署zookeeper节点，尽量偶数个，平均分配到不同的机房中

    选主流程：3个节点相互给两个节点投票，票的信息包含本节点的届号，zxid，myid，其他节点收到后就依次比较，如果比自己的大，就会将该投票信息再次发送给其他节点
    当某个节点的投票数超过半数就被选举为master节点，其他节点则为follower节点


http 1.0 1.1 2.0 3.0  的区别


    HTTP 1.0
    无状态，无连接
    短连接：每次发送请求都要重新建立tcp请求，即三次握手，非常浪费性能
    无host头域，也就是http请求头里的host，
    不允许断点续传，而且不能只传输对象的一部分，要求传输整个对象


    HTTP 1.1
    长连接，流水线，使用connection:keep-alive使用长连接
    请求管道化
    增加缓存处理（新的字段如cache-control）
    增加Host字段，支持断点传输等
    由于长连接会给服务器造成压力


    HTTP 2.0
    二进制分帧
    头部压缩，双方各自维护一个header的索引表，使得不需要直接发送值，通过发送key缩减头部大小
    多路复用（或连接共享），使用多个stream，每个stream又分帧传输，使得一个tcp连接能够处理多个http请求
    服务器推送（Sever push）


    HTTP 3.0
    基于google的QUIC协议，而quic协议是使用udp实现的
    减少了tcp三次握手时间，以及tls握手时间
    解决了http 2.0中前一个stream丢包导致后一个stream被阻塞的问题
    优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗
    连接迁移，不再用tcp四元组确定一个连接，而是用一个64位随机数来确定这个连接
    更合适的流量控制
    基于UDP实现
    0RTT建连
    基于UDP的多路复用
    加密认证的报文
    向前纠错机制

为什么要使用mq
    主要解决三种问题：
    1：多个系统耦合度高的情况下，可以使用mq进行解耦
    2：多个系统之间调用不需要同步的时候，或者说同步调用很耗时的的情况下，使用mq进行异步处理
    3：削峰

    对比：rabbit 基于 erlang 开发，并发能力很强，性能极好，延时很低
         RocketMQ 10万级支持高吞吐量， topic 可以达到几百/几千的级别，分布式架构
         Kafka   10 万级，高吞吐，一般用在大数据领域，topic 从几十到几百个时候，吞吐量会大幅度下降，分布式架构
         手写消息队列你会如何设计：考虑伸缩，需要将数据进行分区，每个分区放一部分数据，每个分区放在不同节点上
                                 考虑数据落盘，这样才能保证服务挂了，数据不丢
                                 考虑可用性，需要与多副本，保证leader挂了，有slave节点顶上来

redis 主从复制原理：

      全量复制

          1：master 执行bgsave，在本地生成一份rdb快照文件
          2：master node 将rdb快照文件发送给slave node，如果rdb 复制时间超过60秒（repl-timeout）,那么slave node 就会认为复制失败，可以适当调节大这个参数
          3：对于千兆网卡的机器，一般每秒传输100MB,6g 文件，很可能超过60s
          4: master node 在生成rdb时，会将所有新写命令缓存在内存中，在slave node 保存了rdb之后，再将新的写命令复制给slave node
          5：client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败
          6：slave node 接收到rdb 后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务
          7：如果slave node 开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF

      增量复制

          1：如果全量复制过程中，master-slave网络连接断掉，那么slave重新连接master时，会触发增量复制
          2: master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认baclog就是1MB
          3: master就是根据slave发送的psync中的offset来从backlog中获取数据的
redis 事务

    redis 事务是一个弱事务。在语法错误时，它能够进行自动回滚，而在没有语法错误，而是在key上使用不是key本身类型的命令时，
    此时该命令执行失败，但是前面已经执行的成功的命令并不能进行回滚。

redis 哨兵工作原理：

      首先进行监控，并且所有的哨兵同步信息。

      哨兵向订阅里边发布信息。

      故障转移：哨兵发现主节点下线→哨兵开启投票竞选负责人→由负责人推选新的主节点→新的主节点断开原主节点，并且其他的从节点连接新的主节点，原主节点上线后作为从节点连接。

如何让系统从未分库分表动态切换成分库分表：

    1：停机迁移方案，挂通知比如某个时间段系统停止对外服务，此时开始将单库单表中的数据读出来，然后通过数据库中间件，写到分库分表中，然后修改数据源配置，包括代码改动，上线部署

    2：双写迁移方案，除了对老库增删改，都加上对新库的增删改，这就是所谓的双写，同时写俩库，老库和新库，老库的数据再导入到新库中，然后对比两边的差异，直到一致，最后部署最新的代码上线

如何设计一个永不迁移的分库分表的方案：

    1：一次性分个够
    2：先范围(保证数据不迁移)，然后再hash(保证数据均匀)


CopyOnWriteArrayList的底层原理是怎样的

    add 方法会加锁，然后对array进行copy，在copy的数组的基础上进行修改，
    读取不会加锁，直接读取原array, 这样就是读写分离思想，适合读多写少的场景
    由于读取的原数组，所以实时性可能不高


HashMap 扩容原理

    1.7：数组要生成一个新的，容量是之前的2倍，然后将原数组上的数据转移到新数组上，就涉及到重新hash，采用的头插法，如果刚好旧链表的两个前后重新hash后也在同一个链表上，旧链表前面的元素会被插入到新链表的后面去
         如果多个线程同时扩容可能会出现死循环

    1.8：数组也要生成一个新的

ConcurrentHashMap的扩容机制

    1.7：
        1：1.7版本的ConcurrentHashMap是基于Segment分段实现的
        2：每个Segment相对于一个小型的HashMap
        3: 每个Segment内部会进行扩容，和HashMap的扩容类似
        4：先生成新的数组，然后转移元素到新数组中
        5：扩容的判断也是每个Segment内部单独判断的

    1.8：
        1：不在基于Segment实现
        2：当某个线程进行put时，如果此时正在扩容，这协助扩容
        3：支持多个线程同时扩容
        4：扩容之前也先生成一个新数组
        5：在转移元素时，先将原数组分组，将每组分给不同的线程进行元素转移，每个线程负责一组或多组元素的转移


跨域解决方法：

    受浏览器安全限制，当请求的接口不是浏览器当前打开的域名时，该请求的结果不会被浏览器接收，解决方案就是
    1：在response添加header，比如resp.setHeader("Access-Control-Allow-Origin"),表示可以访问所有网站，不受是否同源限制
    2：jsonp方式，该技术底层就是基于script标签来实现的，因为script标签可以跨域
    3：后台自己控制，先访问同域名下的接口，然后在接口中再去使用HttpClient等工具请求目标接口
    4：网关，和第三种方式类似，都是交给后台服务来进行跨域访问



ApplicationContext和BeanFactory的区别

    BeanFactory是创建bean的工厂，spring所有bean的生成都由这个接口提供，而ApplicationContext继承BeanFactory接口，
    BeanFactory拥有的功能他也有，只不过他还继承了其他接口，比如事件发布接口，环境变量接口，国际化接口等

Spring中的事务是如何实现的

    1：spring的事务是基于数据库事务和AOP实现的
    2：对于使用事务注解的类，spring会为其创建一个代理类
    3：当调用带有事务注解的方法时，spring会通过事务管理器去找数据库拿一个连接，并将这个连接自动提交设置为false,并将这个连接对象绑定到当前线程上
    4: 然后执行业务代码，执行完毕后没有异常就提交事务，出现异常后根据情况回滚事务
    5：spring的事务隔离级别就是数据库的隔离级别
    6：spring事务的传播机制是spring事务自己实现的，也是基于当前线程绑定的连接来做的


Spring的事务注解什么时候会失效

    1：Spring的事务是基于代理实现的，只有加了事务注解的方法被代理类调用时，事务才会生
    2：私有方法上加事务注解，私有方法调用本身是无法被外部类调用的，只能被类自己中的方法调用，也就是无法走代理


Spring 容器启动的流程

    1：在创建Spring容器时，也就是启动Spring，也就是调用refresh方法就开始spring容器启动了
    2：首先就是需要扫描得到所有的BeanDefinition对象，扫描的具体类就是基于注解的ConfigurationClassPostProcessor类来处理，具体就是解析如下注解
             先解析是否包含@Component注解
             然后解析是否包含@PropertySources注解
             然后解析是否包含@ComponentScans注解
             然后解析是否包含@Import注解
             然后解析是否包含@ImportResource注解
             然后解析方法是否包含@Bean注解
             然后解析接口方法是否包含@Bean注解
             然后查看是否包含父类，包含就再次解析一遍

    3：收集完后就要根据BeanDefinition对象创建Bean了，条件就是排除掉懒加载和多例bean，默认只会创建单例bean

    4:  创建bean的过程中就涉及到bean的声明周期，推断构造方法，实例化，属性注入（Autowired注解的处理），初始化前置处理（PostConstruct注解的处理），
        初始化（Aware接口，InitializingBean接口的处理），初始后后置处理（包含了使用AOP创建代理对象）
        所有bean创建完毕后，进行SmartInitializingSingleton，SmartLifecycle接口的处理，然后发送容器刷新完毕事件

Spring用到了那些设计模式：

    工厂模式：BeanFactory,FactoryBean
    代理模式：AOP
    观察者模式：事件发布监听
    策略模式：MVC参数的解析，响应值的解析
    模板模式：jdbcTemplate
    装饰器模式：spring事务框架对spring cache的支持
    责任链模式：mvc拦截器处理流程
    适配器模式：AdvisorAdapter

SpringMVC的底层工作流程

    1：用户发送请求到前端控制器DispatcherServlet
    2: DispatcherServlet收到请求调用HandlerMapping处理器映射器
    3：处理器映射器找到具体的处理器（可以根据xml配置，注解进行查找），生成处理器及处理器拦截器
    4：后面再由HandlerAdapter处理器适配器
    5：HandlerAdapter经过适配调用具体的处理器Contorller(会涉及到参数解析器，返回值解析器)
    6: 然后返回ModelAndView
    7: DispatcherServlet将ModelAndView传给ViewReslover视图解析器，返回具体的view

Mybatis优缺点

    1: 和jdbc相比减少了50%的代码量
    2：基于sql编程，解耦了代码和sql
    3: 很好的和其他数据库兼容，mybatis之和jdbc打交道
    4：和spring结合的很好
    5：sql语言依赖数据库，不能很好的移植
    6：sql语言编写的工作量比较大

Mybatis #{}，${} 符号的区别


    1：#{} 是预编译的防止sql注入
    2：${} 是字符串拼接，不是预编译的


什么是ZAB协议

    1：领导选举阶段，从Zookeeper集群中选出一个节点作为Leader，所有的写请求都会由Leader节点来处理
    2：数据同步阶段，集群中的所有节点的数据要和Leader保持一致，如果不一致则要进行同步
    3：请求广播阶段，当Leader节点接收到写请求时，会利用两阶段提交来广播该写请求，使得写请求一样在其他节点
       执行，达到节点上的数据实时一致


zookeeper中的领导选举流程

    1：集群中的各个节点首先都是观望状态（LOOKING），一开始都会投票给自己，认为自己比较适合leader
    2: 然后相互投票，每个节点会收到其他节点发过来的选票，然后pk,先比较zxid，大的获胜，相等则比较myid
    3： 一个节点收到其他节点发过的选票，经过pk后，如果pk失败，则改票，此节点就会投给zxid或myid更大的节点
        并将选票放入自己的投票箱中，并将新的选票发送给其他节点
    4：如果pk是平局则将收到的选票放入到自己的投票箱中
    5：如果pk赢了，则忽略所接收的选票
    6：当一个节点将一张选票放入到自己的投票箱值后，就会从投票箱中统计票数，看是否超过一半的节点和自己所投的节点
       一样，如果超过半数，那么则认为当前自己所投的节点是leader
    7: 集群中每个节点都会经过同样的流程，pk的规则也是一样的，一旦改票就会告诉其他服务器，所以最终各个节点的
       投票箱中的选票也是一样的，所以各个节点最终选出来的leader也是一样的

       1 2 3 个节点开始投票，
       第一轮：1节点给自己投一票，2节点给自己投一票，3节点给自己投一票，然后相互投
       第二轮：2,3给1投的自己的票pk失败，1节点投票箱中没有票，1,3给2投的票，2接收1的票pk失败，改票为1，并将1又投给1,3，2接收3的票，pk赢了不做任何操作
              1,2投给3的票，3接收到1的票pk失败，改票为1，并将1有投给1,2, 2接收3的票，pk赢了不做任何操作
       第3轮：此时1,2,3 均搜到1的投票，自己投的票和投票箱的票统计，1的票超过半数了，1就选为了leader


Dubbo支持的负载均衡策略

    1：随机：从多个服务提供者随机选择一个来处理本次请求，调用量越大分布均匀，并支持按权重设置随机概率
    2：轮询：依次选择服务 提供者来处理请求，并支持按权重进行轮询，底层采用的是平衡加权轮询算法
    3：最小活跃调用数：统计服务提供者当前正在处理的请求，下次请求过来则交给活跃数最小的服务器来处理
    4：一致性hash: 相同参数的请求总是发到同一个服务提供者

 Dubbo 是如何完成服务导出的

    1：首先Dubbo会将程序员所使用的@DubboService注解或@Service注解进行解析得到程序员所定义的服务参数
       包括定义服务名，服务接口，服务超时时间，服务协议等等，得到一个ServiceBean

    2: 然后调用ServiceBean的export方法进行服务导出

    3：然后将服务信息注册到注册中心，如果有多个协议，多个注册中心，那就将服务按单个协议，单个注册中心进行注册

    4： 将服务信息注册到注册中心后，还会指定一些监听器，监听动态配置中心的变更
    5： 还会根据服务协议启动对应的Web服务器或网络框架，比如Tomcat，Netty

Dubbo 是如何完成服务引入的

    1：当程序员使用@Referece注解来引入一个服务时，Dubbo会将注解和服务的信息解析出来，得到当前所引用的服务名，服务接口是什么
    2：然后从注册中心进行查询服务信息，得到服务的提供者信息，并存在消费端的服务目录中
    3：并绑定一些监听器用来监听动态配置中心的变更
    3：然后根据查询得到的服务提供者信息生成一个服务接口的代理对象，并放入Spring容器中作为Bean


Spring Cloud 和Dubbo有哪些区别

    SpringCloud 是一个微服务框架，提供了微服务领域中的很多功能组件，Dubbou一开始是一个RPC调用框架，核心是解决服务调用间的问题
    SpringCloud 是一个大而全的框架，Dubbo则更侧重于服务调用，所以Dubbo所提供的功能没有Spring Cloud全面，但是Dubbo的服务调用
    性能比SpringCloud 高，不过SpringCloud和Dubbo并不是对立的，可以结合起来使用


什么是服务熔断，什么是服务降级，区别是什么

    服务熔断是指，当服务A调用的某个服务B不可用时，上游服务A为了保证自己不受影响，从而不再调用服务B，直接返回一个结果，减轻
    服务A和服务B的压力，直到服务B恢复，这种场景熔断和降级是一起出现的

    服务降级除了服务熔断外还有一种开关降级，比如监控到服务负载很高，直接关闭非核心业务，只开放核心业务

    其实应该要这么理解:服务降级有很多种降级方式！如开关降级、限流降级、熔断降级!   服务熔断属于降级方式的一种！

SOA,分布式，微服务之间的关系和区别

    1：分布式架构是指将单体架构中的各个部分拆分，然后部署到不同的机器或进程中，SOA和微服务基本上都是分布式架构的
    2：SOA是一种面向服务的架构，系统的所有服务都注册在总线上，当调用服务时，从总线上查找服务信息，然后调用
    3：微服务是一种更彻底的面向服务的架构，将系统中各个功能抽成一个个小的应用程序，基本保持一个应用对应一个服务


BIO,NIO,AIO分别是什么

    1：BIO 同步阻塞IO,使用BIO读取数据时，线程会阻塞住，并且需要线程主动去查询是否有数据可读，而且需要处理完一个Socket之后才能处理下一个Socket
    2: NIO 同步非阻塞IO,使用NIO读取数据时，线程不会阻塞，但需要线程主动的去查询是否有IO事件
    3：AIO 也叫做NIO 2.0 异步非阻塞IO，使用AIO 读取数据时，线程不会阻塞，并且当有数据可读时会通知给线程，不需要线程去主动查询

零拷贝：

    零拷贝指的是，应用程序在需要把内核中的一块数据转移到另外一块内核区域时，不需要经过先复制到用户空间，再转移到目标区域，而是直接实现转移

kafka pull push 消息的优缺点

    pull 消费者可以自己控制消息的消费进度，但是可能获取不到消息
    push 消费者不能控制消息的消费进度，如果消费者消费的过慢的话，会后消息堆积的情况

TCP的3次握手和4次挥手

    3次握手：

        1：客户端向服务器发送一个SYN
        2：服务端接收到SYN后，给客户端发送一个SYN_ACK
        3: 客户端接收到SYN_ACK后，再给服务端发送一个ACK

    4次挥手：

        1：客户端向服务端发送FIFN
        2：服务端接收FIFN后，向客户端发送ACK，表示我接收到了断开连接的请求，客户端可以不发送数据了，不过服务端这边可能还有数据正在处理
        3：服务端处理完所有数据后，向客户端发送FIFN，表示服务端现在可以断开连接
        4：客户端收到服务端的FIFN，向服务端发送ACK，表示客户端也会断开连接了

ACID靠什么保证的

    A 原子性由undo log 日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的SQL
    C 一致性由其他三大特性保证，程序代码要保证业务上的一致性
    I 隔离性由MVCC来保证
    D 持久性由内存+redo log 来保证，mysql修改数据库同时在内存和redo log 记录这次操作，宕机的时候可以redo log 恢复

一致性模型

    强一致性：当更新操作完成之后，任何多个后续进程的访问都会返回最新的更新后的值
    弱一致性：系统在数据写入成功之后，不承诺立即可以读到最新写入的数据，也不会具体的承诺多久之后可以读到
    最终一致性：最终一致性是弱一致性的特例，强调的是所有数据副本，在经过一段时间的同步之后，最终都能够达到一个一致的状态
    因果一致性：要求有因果关系的槽

    ZooKeeper的写操作实现了强一致线性化，读又实现了顺序一致性
    ZooKeeper的读操作是不做串行化的，否则过于影响读取性能了。客户端会缓存自己见到的最大的zxid，如果与任何server建立session时发现，这个server最近更新的数据比自己还旧，那server端是会拒绝建立session的。也就是说，客户端侧在任何情况下都不会得到更老的数据，这又实现了顺序一致性。

Mysql数据库中，什么情况下设置了索引但无法使用

    1：没有符合最左前缀原则 （多列索引）
    2：字段进行了隐式数据类型转化 （如果主键是字符串的话，使用数字去查询则不会进行转换，就不会走索引）
    3：走索引没有全表扫描效率高

mysql索引对数据库性能的影响

    1：普通索引，允许被索引的数据列包含重复值
    2：唯一索引，可以保证数据记录的唯一性
    3：主键，特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录
    4：联合索引，索引可以覆盖多个数据列，
    5：全文索引，通过建立倒排索引，可以极大的提升检索效率，解决判断字段是否包含的问题

    索引可以极大的提高数据的查询速度
    通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能，但是会降低插入，删除，更新表的速度，因为在执行这些写操作时，还要操作索引文件
    索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚蔟索引，那么需要的空间就会更大，如果非聚集索引非常多，一旦
    聚集索引改变，那么所有非聚集索引都会跟着变

Dubbo 不用jdk的SPI,而要自己实现

    java spi缺点:

        1:需要遍历所有实现并实例化，假设一个实现类初始化过程比较消耗资源且耗时，但是你的代码里面又用不上它，这就产生了资源的浪费，也无法准确引用
        2：没有使用缓存没load都需要重新加载

     dubbo spi

        1:给每个实现类配了个名字，通过名字去文件里面找到对应的实现类全限定名然后加载实例化，按需加载
        2：增加了缓存存储实例，提高读取性能
        3：提供了对IOC和AOP等高级功能的支持，以实现更多类型的扩展

如何实现接口的幂等性

    1：唯一id,每次操作，都根据操作的内容生成唯一的id，在执行之前先判断id是否存在，如果不存在则执行后续操作，并保存到数据库或者redis中（根据请求body生成md5码，放到redis 10秒后过期）
    2：服务端提供发送token的接口，业务调用接口前先获取token,然后调用业务接口时，把token携带过去，服务器判断token是否存在redis中，存在表示第一次请求，可以继续执行业务，执行完业务后，
       最后需要把redis中的token删除

    3：建去重表，将业务中有唯一标识字段保存到去重表，如果表中存在，则表示已经处理过了
    4：版本控制，增加版本号，当版本号符合时，才能更新数据
    5：状态控制，例如订单状态已支付，未支付，支付中，支付失败，当处理于未支付的时候才允许修改为支付中等


Zookeeper watch机制只能用一次的原因

    客户端事件一次性的原因大致是因为节点数据变更后，而你的监听事件还在，也就你的监听事件从来都是增加，而不会减少，ZooKeeper对象对这些事件存在强引用，如果说一直添加事件，这样会导致内存泄漏

zk 中的观察者机制

    观察者的设计是希望能动态扩展zookeeper集群又不会降低写性能
    如果扩展节点是follower，则写入操作提交时需要同步的节点数会变多，导致写入性能下降，而follower又是参与投票的，也会导致投票成本增加
    observer是一种新的节点类型，解决扩展问题的同时，不参与投票，会获取投票结果，同时也可以处理读请求，写请求转发给leader,负责接收leader同步过来的提交数据
    observer的节点故障不会影响集群的可用性


zookeeper 的典型应用场景

    1：数据发布/订阅：配置中心
    2：负载均衡：提供服务者列表
    3：命名服务：提供服务名到服务地址的映射
    4：分布式协调/通知：watch机制和临时节点，获取节点的任务进度，通过修改节点发出通知
    5：集群管理：是否有机器退出和加入，选举master
    6: 分布式锁，分布式队列


分片缓存寻址方案

    1：hash 取模 （节点数变更后，旧的数据都会出问题，全部数据都要重新取模）
    2： 一致性hash （通过hash算法，hash值总是分布在一个范围内，节点变更后，只是部分数据出问题，可能存在数据倾斜问题，可以用虚拟节点提升数据分布的平衡性）
    3: hash 槽 （数据只和槽位绑定，槽位和节点绑定，节点变化，移动槽位就行） HASH_SLOT = CRC16(key) mod 16384


两阶段提交，三阶段提交

    两阶段提交
        1：第一阶段，每个参与者执行本地事务但不提交，进入reday状态，并通知协调者已经准备就绪
        2：第二阶段，当协调者确认每个参与者都ready后， 通知参与者进行commit操作，如果有参与者fail，则发送rollback命令，各参与者做回滚

     问题：

        单点故障，一旦事务管理器出现故障，整个系统不可用
        数据不一致，在阶段二，如果事务管理器只发送了部分commit消息，此时网络发送异常，那么只有部分参与者者接收到commit消息，也就是只有部分参与者提交了事务，使得系统数据不一致
        响应时间较长：参与者和协调者资源都被锁住，提交或者回滚之后才能释放
        不确定性：当事务管理器发送commit之后，并且此时只有一个参与者收到了commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定哪条消息已进提交成功

    三阶段提交：

        1:1阶段，发送canCommit消息，确认数据库环境正常
        2:2阶段，发送PreCommit消息，完成sql语句的操作，但未提交事务
        3:3阶段，发送DoCommit消息，通知所有库提交事务/回滚事务


Dubbo 注册中心有哪些

    zk,nacos,redis,multicast(组播协议，去中心，provider，consumer，不能跨机房，只要广播地址一样，就可以相互发现)

Dubbo 支持的协议有哪些

    Dubbo协议，RMI,Hessian,http,webservice,thrif


数据库3范式：

    　第一范式（1NF）：字段不可分；
    　第二范式（2NF）：有主键，非主键字段依赖主键；
    　第三范式（3NF）：非主键字段不能相互依赖。


DDD

    DDD只是一种方法论，没有一个稳定的技术框架，DDD要求领域是跟技术无关，跟存储无关，跟通信无关


微服务的优缺点

	优点：逻辑清晰，简化部署，可扩展，灵活组合，技术异构，高可靠（故障隔离），应用的性能得到提高，更容易组合专门的团队，代码复用（基础服务可以在整个微服务系统中通用）
	缺点：复杂度高，运维复杂（需要监控系统），影响性能（链路调用长）


微服务如何去拆分

    单一职责，高内聚，低耦合
    先粗粒度再细粒度
    产品迭代的同时去拆分，先拆分非核心业务，减少影响
    微服务之间尽量不要有义务交叉
    微服务之间通过接口进行服务调用，而不能绕过接口直接访问对方的数据
    高内聚，低耦合（是一种从上而下指导微服务设计的方法，实现高内聚低耦合的工具主要有同步的接口和移不动事件驱动两种实现方式）

微服务如何保证敏捷开发，微服务的链路追踪，持续集成，AB发布要怎么做

    敏捷开发：目的就是为了提高团队的交付效率，快速迭代，快速试错
    每个月固定发布新版本，以分支的形式保存到代码仓库中，快速入职


限流算法

    计数器法：

        在固定时间范围内，只能允许一定的数量通过，存在的问题就是临界问题，如果所有请求都是在最后一小段时间来的，然后下一段时间所有请求在最前面一段时间，此时就会超额

    滑动窗口计数器：

        把一个时间分为更小的时间片，每个时间片的总请求数不能大于阈值，当一个时间片过后，进入到下一个时间片，下一个时间片的请求数加上当前的请求数不能大于阈值，并把新增一个空的时间片

     漏桶算法：

         不管来多少请求，永远以固定的速率去处理请求，不能处理请求突发情况


     令牌算法：

          往桶里方令牌，令牌数能超过阈值，以固定速率去方令牌，比如桶的总令牌数是20，每秒放10个，那么就可以极限处理每秒20个请求


Kafka 是pull 还是 push
    Kafka选择的是pull模式，rabbitmq,roketmq （pull,push都有）
    pull模式：

        根据consumer的消费能力进行数据拉取，可以控制速率
        可以批量拉取，也可以单条拉取
        可以设置不同的提交方式，实现不同的传输语义

     缺点：如果kafka没有数据，会导致consumer空循环，消耗资源
     解决：通过参数设置，consumer拉取数据为空或者没有达到一定数量时进行阻塞

     push模式：不会导致consumer循环等待
     缺点：速率固定，忽略了consumer的消费能力，可能导致拒绝服务或者网络拥塞等情况

Kafka为什么吞吐量大，速度快

    顺序读写，Page Cache(避免Object消耗，避免GC问题)，零拷贝，分区分段+索引，批量读写，批量压缩


Kafka消息高可靠解决方案

    消息发送：
        ack: 0 不重试，1，lead写入成功就返回了，all/-1 等待ISR同步完再返回
        unclean.leader.election.enable:false, 禁止选举ISR以外的follower为leader
        tries > 1 重试次数
        min.insync.replicas > 1: 同步副本数，没满足该值前，不提供读写服务，写操作会异常

    消费：

        手工提交offset
        broker:减小刷盘间隔
        事务消息


Kafka消息丢失的场景及解决方案

    1：ack=0 不重试
    2：ack=1 leader crash
        producer 发送消息，只等待lead写入成功就返回了，leader crash了，这时follower没来得及同步，消息丢失

    3：unclean.leader.election.enable 配置true
       允许选举ISR以外的副本作为leader,会导致数据丢失，默认false

    解决方案

        1：配置ack=all/-1, tries > 1,unclean.leader,election.enable:false,min.insync.replicas > 1
        min.insync.replicas > 1 该参数只有在ack=all/-1时才有用
        失败offset单独记录
        producer发送消息，会自动重试，遇到不可恢复异常会抛出，这时可以捕获异常记录到数据库缓存，进行单独处理


Kafka中zk的作用

    /brokers/ids: 临时节点，保存所有broker节点信息，存储broker的物理地址，版本信息，启动时间等，节点名称为brokerID,broker定时发送心跳到zk,如果断开则brokerID会被删除
    /brokers/topics: 临时节点，节点保存broker节点所有的topic信息，每一个topic节点下包含一个固定的partitions节点，partitions的子节点就是topic的分区，每个分区下保存一个state节点
                     保存当前leader分区和ISR的brokerID,state节点由leader创建，若leader宕机该节点会被删除，直到有新的leader选举产生，重新生成state节点
    /consumer/[group-id]/owners/[topic]/[broker_id-patition_id]:维护消费者和分区的注册关系
    /consumer/[group_id]/offsets/[topic]/[broker_id-pattition_id]: 分区消息的消费进度offset

    client通过topic找到topic树下的state节点，获取leader的brokerID,到broker树中找到broker的物理地址，但是client不会直连zk ,而是通过配置的broker获取到zk中信息

 rabbitmq 的镜像队列原理

    GM负责消息的广播，所有的GM组成gm_group,形成链表结构，负责监听相邻节点的状态，以及传递消息到相邻节点，master的GM收到消息时代表消息同步完成

    mirro_queue_master/slave负责消息的处理，操作blockingQueue，Queue负责AMAP协议

rabbitmq 是否可以直连队列

    可以

Kafka的rebalance机制

    consumer group中的消费者与topic下的partion重新匹配的过程
    何时会产生rebalance:
        consumer group 中的成员个数发生变化
        consumer消费超时
        group订阅的topic个数发生变化
        group订阅的topic的分区发生变化

    coordinator： 通常是partition的leader节点所在的broker,负责监控group中consumer的存活，consumer维持到coordinator的心跳
                  判断consumer的消费超时

                  coordinator通过心跳返回通知consumer进行rebalance
                  consumer请求coordinator加入组，coordinator选举产生leader consumer
                  leader consumer 从 coordinator 获取所有的consumer，发送syncGroup分配信息给到coordinator
                  coordinator通过心跳机制将syncGroup下发给consumer
                  完成rebalance


Kafka 几种消息位置标示

    LEO：下一个消息写入的位置
    HW：HW之前的消息才能被消费者看到（取决于ISR中最小的HW）
    firstUnstableOffset: 第一条未提交的数据
    LastStateOffset: 最后一条提交数据
    LogStartOffset: 起始位置

    isolation.level=read_committed: 只能消费到LastStableOffset, read_committed可以消费到HW的上一条
    一个pattition对应的ISR中最小的LEO作为分区的HW，consumer最多只能消费到HW所在的位置
    leader收消息后会更新本地的LEO，leader还会维护follower的LEO即remote LEO,follower发出fetch同步数据
    请求时（携带自身的LEO），leader会更新remote LEO,更新分区的HW，然后将数据响应给follower，follower更新
    自身HW（取响应中的HW和自身的LEO中较小值），LEO+1
    ISR：如果一个follower落后leader不超过某个时间阈值，那么则在ISR中，否则放到OSR中

    同步副本时，follower获取leader的LEO和LogStartOffset，与本地对比，如果本地的LogStartOffset超出了leader的值，则超过这个值的数据删除，再进行同步，如果本地的小于leader的
    则直接同步


让你设计一个MQ，你会如何设计

    1：实现一个单机的队列数据结构，高效，可扩展
    2：将单机队列扩展成分布式队列，分布式集群管理
    3：基于topic定制消息路由，发送者路由，消费者与队列对应的关系，消费者路由策略
    4：实现高效的网络通信 Netty
    5: 规划日志文件，实现文件高效读写，零拷贝，顺序写
    6：定制高级功能，死信队列，延迟队列，事务消息

zk的一致性

    后面这句话厉害了，ZooKeeper的一致性实际是处于强一致性和顺序一致性之间，为什么这样说呢？

    因为客户读链接ZooKeeper集群后，所有的写操作都必须发送给集群唯一的leader，这个leader在内部同步块中赋予每个写操作一个顺序（zxid单调增），上一个写操作不commit，下一个写操作就不执行，这一点实际上已经实现了写入的强一致性（线性化）了！

    但ZooKeeper的读操作是不做串行化的，否则过于影响读取性能了。客户端会缓存自己见到的最大的zxid，如果与任何server建立session时发现，这个server最近更新的数据比自己还旧，那server端是会拒绝建立session的。也就是说，客户端侧在任何情况下都不会得到更老的数据，这又实现了顺序一致性。

ImportSelector的作用
该接口文档上说的明明白白，其主要作用是收集需要导入的配置类，如果该接口的实现类同时实现EnvironmentAware， BeanFactoryAware ，BeanClassLoaderAware或者ResourceLoaderAware，那么在调用其selectImports方法之前先调用上述接口中对应的方法，如果需要在所有的@Configuration处理完在导入时可以实现DeferredImportSelector接口。

强弱引用的区别

    弱引用： 当内存不够时，gc就会被回收
    虚引用： 只要是进行gc就会被回收
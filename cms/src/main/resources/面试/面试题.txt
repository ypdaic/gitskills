
cyclicBarrier 和 countDown用法上的区别：

前者是多个线程相互等待然后一起执行，后者是一个线程等待多个线程然后执行


redis 实现分布式锁

    SET resource_name my_random_value NX PX 30000   值是一个随机值，必须保证唯一性

    解锁用lua脚本去解锁，防止，A线程锁超时后，B线程获取锁成功，A将B的锁给删除掉


Bean的生命周期

    1. 实例化bean
    2. bean 属性设置
    3. arwe接口处理
    4. beanpostprocess 接口前置处理
    5. InitializingBean 接口处理
    6. beanpostprocess 接口后置处理
    7. bean的销毁处理

IOC、AOP

    IOC 就是所有的对象交给spring容器管理，对象的创建，销毁，属性的主动注入
    AOP 就是提供一些切面功能，比如事务切面，缓存切面，等等，核心就是使用代理模式，使用生成的代理实例替代原有的bean，在
        原有bean方法的前后执行一些而外的逻辑，其代理模式有分为jdk动态代理，cglib代理，jdk动态代理只能是对接口进行代理，而
        cglib使用的继承进行代理，也支持只对接口代理，spring默认使用cglib进行代理

HashTable、HashMap、ConcurrentHashMap

    HashTable 是线程安全的，使用sync进行同步，而HashMap 不是线程安全的，ConcurrentHashMap是线程安全的
    ConcurrentHashMap在1.8以前使用分段锁思想，1.8以后则将锁细分到每个node节点，这样并发性能更高

数据库事务的底层实现、Spring事务是如何实现的

    事务底层使用mvcc多版本控制实现的，spring事务则是使用threadlocal将数据源绑定到当前线程上，然后开启事务，后续当前线程的数据库操作
    则在这个事务上进行，spring自己给提供了一个事务传播机制，大概弄了7种传播机制，
    如果当前没有事务，则开启一个事务，
    如果当前没有事务则报错，
    如果当前没有事务则已非事务进行，有事务则在事务中进行
    当前有事务则挂起该事务以非事务的方式执行，
    当前有事务，挂起该事务，并继续使用该事务执行，如果出现错误，则只是回滚挂起点之后的
    当前有事务则挂起该事务，后面开启一个新的事务执行，

Spring如何解决循环依赖

    使用3级缓存解决的，第一级缓存存放实例化完成的对象，第二级缓存存放提前暴露的对象，第三级缓存放对象工厂对象
    解决循环依赖就依靠这三级缓存解决的，比如A依赖b,b依赖c,c又依赖A，当实例化A时，必然要先实例化B，c,而C
    的实例化又依赖A，此时就会回到创建A的逻辑，而在第一次创建A时已经将其放到了第3级缓存中，创建C的过程中
    依赖A就会直接重三级缓存中获取A，并且将三级缓存清空，将其提升到二级缓存，此时二级缓存是一个提前暴露的对象
    如果还存在C中d对象也依赖A的话，就直接从二级缓存中获取，最后A创建完成将二级缓存清空，提升到一级缓存，后面其他对象
    依赖A就直接从一级缓存中获取

线程池的参数及执言行过程

   核心线程池的大小，最大线程池大小，线程空闲时间及空闲时间的单位，阻塞队列，线程工厂，拒绝策略

   执行逻辑就是，当任务数小于核心线程数大小时，则开启新的线程用于处理任务，如果大于核心大小，则将任务放到阻塞队列，如果
   队列满了，则创建新的线程处理任务，如果线程数等于最大线程数了，则要使用拒绝策略了，比如抛异常，或者直接使用丢任务的线程处理，
   或者丢弃老的任务，或者丢弃该任务，当大于核心线程数的线程执行完任务开始获取下一个任务执行时，如果获取时间超过设置的空闲时间
   则该线程会被销毁，也就是超过核心的线程使用poll去获取任务，小于核心数的线程使用take去获取任务

   线程池的销毁也分两组情况，一种是shutdown，一种是shutdownnow ,前者会执行完队列中的任务，并且不会发送中断给线程池中正在执行任务的线程
   后者则是会将队列中的任务拿出来给调用者自己决定要怎么处理这些任务， 并且会发送中断给正在执行任务的线程

MySQL的乐观锁、悲观锁

    乐观锁就是使用版本号，使用cas的思想，循环不断的去比较当前版本号和数据库的版本号是否一致，一致就更新，不一致就是重新获取最新的
    版本号，进行下一次的判断更新

    悲观锁就是上来就加一把锁，如果加锁失败就等待锁，比如使用select for update ，获取锁后在进行下面的操作，
    如果有使用到索引就是行锁，如果没有使用索引则就是表锁

MVCC机制的实现

    其实现就是在开启事务前，会将当前最新的事务id，保存为up_limit_id
    如果更新一条数据的话，则会将这个数据的就记录以及该数据的事务id存到undo_log 中
    然后更新数据页中该记录的值和事务id
    当别的事务要查询该条记录时，如果自己的up_limit_id 小于该条记录的事务id，则会去undo_log中查找，也是找事务id小于up_limit_id的记录


SpringBoot的整个启动流程

    整个逻辑就是从spring.fatoryas 文件中搜集springApplicationrunlister接口的实现
    然后调用starting接口
    然后是环境信前置处理，调用lisenler接口的preaper环境接口
    然后打印banner
    然后开始创建ApplicationContext,这其中开始收集注解，自动配置的配置类，生成beandefeintion对象，然后调用onrefresh方法
    进行webserver的创建，也就tomcat的初始后，
    然后开始bean的创建过程
    这些完毕后，就会调用前面lisenler接口的stared接口
    最后调用ApplicationRunner,CommandLineRunner接口


cglib 和 jdk动态代理的区别

重要的一点在用法上如果注入的具体的实例，jdk动态代理会报类型转换异常，然后CGLIB 默认是自动配置进行配置的


ES的倒排索引、查询的整个流程、如何动态加载新的分词
Java异常类的层次结构

    throwable

     error   exception

             runtimeexcetion

redis的常用数据结构及底层实现



redis、zk的分布式锁的实现

     redis setnx 命令，保证只有有一个线程设置成功
           其次要解决客户端假死，锁无法释放的问题，需要设置锁的过期时间
           还有解决业务执行的时间超过锁过期时间，需要使用定时任务去给锁进行续期
           还要解决锁被误解锁问题，需要使用lua脚本判断该锁的随机码和内存中持有的是否一致
           一致才能释放锁
           还要解决锁重入问题，可以使用threadlocal保存当前线程，如果下次获取锁的还是当前线程者不用再次获取锁了
           直接执行

     zk   主要使用临时有序节点，最小的节点最先获取锁，后续的节点监听前面节点的删除事件，被通知后才进行锁的获取
          由于临时节点不存死锁问题，需要设置锁的过期时间和续期问题，重入可以和redisd的做法一样

rabbitmq如何保证消息的可靠性、顺序性、幂等消费，及使用场景

    rabbitmq 消息可靠性保证可以使用发送者确认和失败通知模式，还有消费者应答模式，结合本地消息表形式加定时任务的
    顺序性生产者使用一个channel进行发送，消费者使用一个队列进行消费，幂等需要在每条消息中加入一个唯一码，使用这个唯一码去查询这个
    消息是否被消费过，消费了就不进行消费了



分布式事务（2pc、3pc、TCC、阿里的seata框架的大概执行流程）

    TCC 主要分为3个过程try,commit，cancer
    try 主要是预留资源
    commit 就是对预留资源处理
    cancer 就是回退预留的资源
    都需要业务端实现

    seata AT 事务，比如在A服务开启全局事务，A需要开启本地事务，然后会生成beforeimage 执行本地事务，afterimage, 和本地事务一起插入到undo_log表中g

    然后开始调用B服务，比如是使用fegin调用的，此时会将全局事务id放到fegin的请求头中，B服务使用springmvc的拦截器获取到全局事务id，并绑定到当前线程中
    然后数据源代理对象检测到存在全局事务id后，一样会生成beforeimage afterimage 和本地事务一起插入到undo_log表中，并且向TM插入一个分支事务
    然后提交本地事务，向TM上报分支事务执行状态，此时回到A服务，也是注册分支事务，如果此时发生异常，会上报分支事务的状态，本地事务回滚，TM是发送异步回滚事件通知
    B服务进行回滚，回滚就将数据更新成beforeimage的状态

CAS、volatile、Java内存模型、内存屏障

   CAS 就是比较与交换，使用内存中的值和主内存中值进行比较，如果相等则更新主内存中的值，如果不相等则获取最新主内存中的值，循环等待下次比较

   volatile 只能保证可见性，不能保证原子性，volatile可以防止指令重排序，防止指令重排序则依靠内存屏障，比如storestore,storeload,loadload,loadstore



JVM的堆外内存

   元空间

怎么判断可能存在内存泄漏


    多次full gc 回收的内存很小了，就可能存在内存泄漏

多大的对象直接放入到老生代

    -XX:PretenureSizeThreshold=4m

3色标记法

    黑色 gcroot
    灰色 正在扫描
    白色 已经扫描完成，并且可以被回收

CMS和G1的执行流程及G1的好处

    CMS

    初始标记，并发标记，重新标记，并发清除，初始标记和重新标记会有暂停，而并发标记，并发清除，则是和应用线程一起进行

    G1
    初始标记，并发标记，最终标记，筛选回收，初始标记，最终标记会有暂停，并发标记，筛选回收，则和应用程序一起进行
    G1 追求可以预测的挺顿

synchronized（jdk8的优化点）和reentrantLock的底层实现及区别

   锁升级，偏向锁，轻量级锁，重量级锁
   jdk 实现

AQS的组成及加锁过程

    AQS就是CLH队列锁的变种实现，内部使用node形成一个双向链表，每个node包含了前驱节点，后续节点和当前线程引用
    加锁过程就是，先获取信号量，如果获取信号量失败就创建一个等待node节点，添加到队列尾部，设置前驱节点，然后判断前驱
    节点是否是head节点，如果是的话，继续获取信号量，如果获取成功就加锁成功，如果获取失败就等待，等待被前驱节点唤醒

redo log、undo log、binlog的作用、两阶段提交…

 redo log 用于保证数据库crash_safe 的能力
 binlog 用于主从数据同步
 undo log 用于事务隔离

 两阶段提交：

    redo log perpra

     bin log 写入

     redo log 提交

     当在2之前崩溃时
     重启恢复：后发现没有commit，回滚。备份恢复：没有binlog 。一致

     当在3之前崩溃
     重启恢复：虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。备份：有binlog. 一致

BIO、NIO、AIO的区别

    BIO 阻塞IO
    NIO 多路复用IO
    AIO 真正的异步IO

mmap、零拷贝

    零拷贝就是没有将堆外内存拷贝到堆内存的过程，而是直接操作堆外内存

类加载机制

    遵从找父类加载器进行加载，父类加载不到，自己才进行加载

dubbo的执行流程，http和RPC的关系，dubbo和SpringCloud Feign的区别

SpringBoot Starters的优点

    开发人员不用自己手动配置别人提供的功能，该配置那些功能，而且还能参考别人的配置，搞清楚该如何去配置去使用第三方提供的功能

按整个项目的执行流程，介绍SpringCloud的各个组件
访问域名www.baidu.com的整个流程
websocket的底层实现

缓存穿透、缓存雪崩、缓存击穿

   缓存穿透：就是使用多个不存在的key去请求，由于redis中没有，请求直接打到数据库了，解决方案有：回种空值，设置较短的过期时间，或者布隆过滤器
   缓存雪崩：大量key同时失效，导致请求全部打到数据库，解决方案：key的过期时间设置随机值，尽量分散开
   缓存击穿：单个key，被大量访问，解决方案：加锁，本地锁，分布式锁

缓存一致性协议（基于具体场景问题，忘记了）

redis哨兵如何通信


redis的过期策略

    惰性删除（get时才去删除），定期删除（随机取部分过期的key进行删除）

RDB、AOF

    RDB：内存数据的快照
    AOF：记录每个执行的每条命令，顺序写
    同时开启的话，加载的AOF

mysql索引优化

    explan 命令type至少是req级别

mysql索引失效原因

     对索引字段进行函数计算，like方法，索引字段有空值，is null,is not null

mysql 死锁如何查询

    执行命令：show engine innodb status （需要在mysql的命令行执行）

mysql的逻辑架构组的组成

redis单线程为什么这么快

   1：基于纯内存操作
   2：IO多路复用，非阻塞的同时监听多个客户端的连接和相关事件
   3：单线程避免上下文切换，和资源竟态竞争


mysql主从复制流程

    master上有dump线程，每次数据变更，master会通知dump线程将数据发送slave,slave上有对应的IO线程和sql线程
    IO线程负责将master推送过来是数据写到relay-bin中，然后sql读取relay-bin的内容进行同步

    默认是异步的，也有半同步，也就是等slave的relay-bin 写成功后master才进行事务的提交

ThreadLoc的底层实现、为什么要使用弱引用，如何防止内存泄漏、开源代码及项目中的使用案例

    Thread 对象本身存在一个ThreadLocalMap 对象，
    以ThreadLocal 为key,存放的值为value
    使用弱引用，怕在线程周期中，ThreadLocal 对象的外部引用不存在，而由于线程一直在运行，ThreadLocalMap中的key,value本该被回收的，不能回收，造成
    内存泄漏，所以用了弱引用，只要GC就进行回收，防止内存泄漏：用于就得remove掉
    使用案例：spring 事务，动态数据源切换

如何解决跨域问题
CompletableFuture、Forkjoinpool的底层实现，该如何使用
介绍一款分布式ID

   雪花算法：41位时间戳，5位机房id,5位机器id,12位同一毫秒生成不同id

Hystrix的熔断、限流、降级

    如果没有触发熔断，且是线程池隔离，则会检查是否超过线程池任务处理数，如果是信号量隔离，则会检查是否能够获取信号量，不满足就走降级，
    如果都满足则会判断是否在时间窗口内超过20个请求，且失败率超过了50%，如果满足的话就会开启熔断，走降级，如果没有则正常请求
    如果已经触发熔断则会5秒中后探测一下是否请求成功，如果成功则关闭熔断，如果失败，再过5秒继续试探

分布式链路如何串联所有span的

TCP、UDP的区别

    TCP 需要客户端连接服务端
    UDP 直接广播

Object有哪些方法，为什么要重写hashcode和equals方法

    重写hashcode 是为了将对象放在MAP中时减少hash冲突
    重写equals 是为了将对象放在MAP中时，判断两个对象相等的依据

创建线程的几种方式，及区别

    实现Runable接口，继承Thread，实现Callable接口
    前两者没有返回值，后置存在返回值

单例对象创建的几种方式，并详细描述

    饱汉模式：类中定义好静态变量，并进行初始化
    懒汉模式：使用sync进行同步
    双重检查：当对象为空时才进行同步，进入到同步块中，再次判断是否为空，为空才进行初始化，初始化后赋值的变量得用volatile修饰，防止指令重排序，类还没初始化完成就被使用的情况

zk的脑裂、选主流程、如何防止脑裂

    脑裂就是zk集群部署在多个机房，两个机房断联了，然后每个机房各自开始进行选主，但是zk是不可能出现脑裂的，比如每个机房3个节点
    选主需要超过半数节点的投票，由于总共6个节点，超过半数就是超过3个节点，然而每个机房只有3个节点，所以整个集群就不可用了，不存在脑裂

    选主流程：3个节点相互给两个节点投票，票的信息包含本节点的届号，zxid，myid，其他节点收到后就依次比较，如果比自己的大，就会将该投票信息再次发送给其他节点
    当某个节点的投票数超过半数就被选举为master节点，其他节点则为follower节点


http 1.0 1.1 2.0 3.0  的区别


    HTTP 1.0
    无状态，无连接
    短连接：每次发送请求都要重新建立tcp请求，即三次握手，非常浪费性能
    无host头域，也就是http请求头里的host，
    不允许断点续传，而且不能只传输对象的一部分，要求传输整个对象


    HTTP 1.1
    长连接，流水线，使用connection:keep-alive使用长连接
    请求管道化
    增加缓存处理（新的字段如cache-control）
    增加Host字段，支持断点传输等
    由于长连接会给服务器造成压力


    HTTP 2.0
    二进制分帧
    头部压缩，双方各自维护一个header的索引表，使得不需要直接发送值，通过发送key缩减头部大小
    多路复用（或连接共享），使用多个stream，每个stream又分帧传输，使得一个tcp连接能够处理多个http请求
    服务器推送（Sever push）


    HTTP 3.0
    基于google的QUIC协议，而quic协议是使用udp实现的
    减少了tcp三次握手时间，以及tls握手时间
    解决了http 2.0中前一个stream丢包导致后一个stream被阻塞的问题
    优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗
    连接迁移，不再用tcp四元组确定一个连接，而是用一个64位随机数来确定这个连接
    更合适的流量控制
    基于UDP实现
    0RTT建连
    基于UDP的多路复用
    加密认证的报文
    向前纠错机制

为什么要使用mq
    主要解决三种问题：
    1：多个系统耦合度高的情况下，可以使用mq进行解耦
    2：多个系统之间调用不需要同步的时候，或者说同步调用很耗时的的情况下，使用mq进行异步处理
    3：削峰

    对比：rabbit 基于 erlang 开发，并发能力很强，性能极好，延时很低
         RocketMQ 10万级支持高吞吐量， topic 可以达到几百/几千的级别，分布式架构
         Kafka   10 万级，高吞吐，一般用在大数据领域，topic 从几十到几百个时候，吞吐量会大幅度下降，分布式架构
         手写消息队列你会如何设计：考虑伸缩，需要将数据进行分区，每个分区放一部分数据，每个分区放在不同节点上
                                 考虑数据落盘，这样才能保证服务挂了，数据不丢
                                 考虑可用性，需要与多副本，保证leader挂了，有slave节点顶上来

redis 主从复制原理：

      全量复制

          1：master 执行bgsave，在本地生成一份rdb快照文件
          2：master node 将rdb快照文件发送给slave node，如果rdb 复制时间超过60秒（repl-timeout）,那么slave node 就会认为复制失败，可以适当调节大这个参数
          3：对于千兆网卡的机器，一般每秒传输100MB,6g 文件，很可能超过60s
          4: master node 在生成rdb时，会将所有新写命令缓存在内存中，在slave node 保存了rdb之后，再将新的写命令复制给slave node
          5：client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败
          6：slave node 接收到rdb 后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务
          7：如果slave node 开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF

      增量复制

          1：如果全量复制过程中，master-slave网络连接断掉，那么slave重新连接master时，会触发增量复制
          2: master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认baclog就是1MB
          3: master就是根据slave发送的psync中的offset来从backlog中获取数据的


redis 哨兵工作原理：

      首先进行监控，并且所有的哨兵同步信息。

      哨兵向订阅里边发布信息。

      故障转移：哨兵发现主节点下线→哨兵开启投票竞选负责人→由负责人推选新的主节点→新的主节点断开原主节点，并且其他的从节点连接新的主节点，原主节点上线后作为从节点连接。

如何让系统从未分库分表动态切换成分库分表：

    1：停机迁移方案，挂通知比如某个时间段系统停止对外服务，此时开始将单库单表中的数据读出来，然后通过数据库中间件，写到分库分表中，然后修改数据源配置，包括代码改动，上线部署

    2：双写迁移方案，除了对老库增删改，都加上对新库的增删改，这就是所谓的双写，同时写俩库，老库和新库，老库的数据再导入到新库中，然后对比两边的差异，直到一致，最后部署最新的代码上线

如何设计一个永不迁移的分库分表的方案：

    1：一次性分个够
    2：先范围(保证数据不迁移)，然后再hash(保证数据均匀)

